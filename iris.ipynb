{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Data sets\n",
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "def main(): #If the training and test sets aren 't stored locally, download them.\n",
    "    if not os.path.exists(IRIS_TRAINING):\n",
    "        raw=urllib.urlopen(IRIS_TRAINING_URL).read()\n",
    "    with open(IRIS_TRAINING, \"w\") as f:\n",
    "        f.write(raw)\n",
    "\n",
    "    if not os.path.exists(IRIS_TEST):\n",
    "        raw=urllib.urlopen(IRIS_TEST_URL).read()\n",
    "    with open(IRIS_TEST, \"w\") as f:\n",
    "        f.write(raw)\n",
    "\n",
    "     # Load datasets.\n",
    "    training_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename = IRIS_TRAINING,\n",
    "    target_dtype = np.int,\n",
    "    features_dtype = np.float32)\n",
    "    test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename = IRIS_TEST,\n",
    "    \n",
    "    target_dtype = np.int,\n",
    "    features_dtype = np.float32)\n",
    "\n",
    "    # Specify that all features have real - value data\n",
    "    feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension = 4)]\n",
    "\n",
    "    # Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "    classifier = tf.contrib.learn.DNNClassifier(feature_columns = feature_columns,\n",
    "    hidden_units = [10, 20, 10],\n",
    "    n_classes = 3,\n",
    "    model_dir = \"/tmp/iris_model\")# Define the training inputs\n",
    "    def get_train_inputs():\n",
    "        x = tf.constant(training_set.data)\n",
    "        y = tf.constant(training_set.target)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "    # Fit model.\n",
    "    classifier.fit(input_fn = get_train_inputs, steps = 2000)\n",
    "\n",
    "    # Define the test inputs\n",
    "    def get_test_inputs():\n",
    "        x = tf.constant(test_set.data)\n",
    "        y = tf.constant(test_set.target)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "    # Evaluate accuracy.\n",
    "    accuracy_score = classifier.evaluate(input_fn = get_test_inputs,\n",
    "    steps = 1)[\"accuracy\"]\n",
    "\n",
    "    print(\"\\nTest Accuracy: {0:f}\\n\".format(accuracy_score))\n",
    "\n",
    "    # Classify two new flower samples.\n",
    "    def new_samples():\n",
    "        return np.array(\n",
    "        [\n",
    "            [6.4, 3.2, 4.5, 1.5],\n",
    "            [5.8, 3.1, 5.0, 1.7]\n",
    "        ], dtype = np.float32)\n",
    "\n",
    "    predictions = list(classifier.predict(input_fn = new_samples))\n",
    "\n",
    "    print(\n",
    "    \"New Samples, Class Predictions:    {}\\n\"\n",
    "    .format(predictions))\n",
    "\n",
    "    if __name__ == \"__main__\":\n",
    "        main ()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
